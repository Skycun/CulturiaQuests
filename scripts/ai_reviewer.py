# scripts/ai_reviewer.py
import os
import sys
import subprocess
import requests
from openai import OpenAI # type: ignore
import json
from typing import List, Optional
from pydantic import BaseModel, ValidationError, Field, field_validator

# --- CONFIGURATION ---
MODEL_NAME = "gpt-5.1-codex-mini"
MAX_CONTENT_LENGTH = 80000  # Augment√© car les diffs sont plus compacts que le contenu complet
MAX_FILES_ANALYZED = 50

DISCORD_WEBHOOK = os.environ.get("DISCORD_WEBHOOK_URL")
API_KEY = os.environ.get("OPENAI_API_KEY")

# Mapping des auteurs Git vers les IDs Discord
AUTHOR_DISCORD_MAP = {
    "skycun": "202033313270071296",
    "lelio88": "479725850590183459",
    "ethanolove": "556125496979619840"
}

# Initialisation du client OpenAI
client = OpenAI(api_key=API_KEY)

# --- VALIDATION SCH√âMA PYDANTIC ---
class ReviewDetails(BaseModel):
    SOLID: int = Field(ge=0, le=20)
    Clarte: int = Field(ge=0, le=20)
    Securite: int = Field(ge=0, le=20)
    Performance: int = Field(ge=0, le=20)

class ReviewReport(BaseModel):
    score_global: int = Field(ge=0, le=20)
    details: ReviewDetails
    resume: str = Field(max_length=200)
    points_forts: List[str] = Field(max_length=5)
    points_faibles: List[str] = Field(max_length=5)
    conseil_mentor: str = Field(max_length=300)
    
    @field_validator('points_forts', 'points_faibles')
    @classmethod
    def validate_list_items(cls, v):
        if not v:
            return ["Aucun point identifi√©"]
        # Limite la longueur de chaque √©l√©ment et sanitation
        return [item[:150].strip() for item in v[:5]]
    
    @field_validator('resume', 'conseil_mentor')
    @classmethod
    def sanitize_text(cls, v):
        # Supprime les caract√®res potentiellement probl√©matiques
        return v.replace('`', '').replace('*', '').strip()

def get_changed_files():
    """R√©cup√®re la liste des fichiers modifi√©s dans le dernier commit"""
    try:
        # On compare le HEAD avec le commit pr√©c√©dent
        result = subprocess.run(
            ["git", "diff", "--name-only", "HEAD~1", "HEAD"],
            capture_output=True, text=True, check=True
        )
        files = result.stdout.strip().split('\n')
        # On ne garde que les fichiers de code pertinents
        valid_files = [f for f in files if f.endswith(('.php', '.vue', '.ts', '.js', '.yaml', '.yml', '.css', '.py')) and os.path.exists(f)]

        if len(valid_files) > MAX_FILES_ANALYZED:
            print(f"‚ö†Ô∏è Trop de fichiers modifi√©s ({len(valid_files)}). Limitation √† {MAX_FILES_ANALYZED} fichiers.")
            return valid_files[:MAX_FILES_ANALYZED]

        return valid_files
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des fichiers: {e}")
        return []

def get_file_diff(filepath: str) -> str:
    """R√©cup√®re le diff d'un fichier sp√©cifique"""
    try:
        result = subprocess.run(
            ["git", "diff", "HEAD~1", "HEAD", "--", filepath],
            capture_output=True, text=True, check=True
        )
        return result.stdout
    except subprocess.CalledProcessError as e:
        print(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration du diff pour {filepath}: {e}")
        return ""

def get_file_stats(filepath: str) -> dict:
    """R√©cup√®re les statistiques d'un fichier (lignes ajout√©es/supprim√©es)"""
    try:
        result = subprocess.run(
            ["git", "diff", "--numstat", "HEAD~1", "HEAD", "--", filepath],
            capture_output=True, text=True, check=True
        )
        stats = result.stdout.strip().split('\t')
        if len(stats) >= 2:
            return {
                "added": int(stats[0]) if stats[0] != '-' else 0,
                "deleted": int(stats[1]) if stats[1] != '-' else 0
            }
    except (subprocess.CalledProcessError, ValueError) as e:
        print(f"‚ö†Ô∏è Erreur stats pour {filepath}: {e}")
    return {"added": 0, "deleted": 0}

def get_commit_info():
    """R√©cup√®re le message, le hash et l'auteur du dernier commit"""
    try:
        # R√©cup√®re le hash court (7 caract√®res)
        hash_result = subprocess.run(
            ["git", "rev-parse", "--short=7", "HEAD"],
            capture_output=True, text=True, check=True
        )
        commit_hash = hash_result.stdout.strip()

        # R√©cup√®re le message du commit (premi√®re ligne uniquement)
        message_result = subprocess.run(
            ["git", "log", "-1", "--pretty=%s"],
            capture_output=True, text=True, check=True
        )
        commit_message = message_result.stdout.strip()

        # R√©cup√®re l'auteur du commit (nom d'utilisateur Git)
        author_result = subprocess.run(
            ["git", "log", "-1", "--pretty=%an"],
            capture_output=True, text=True, check=True
        )
        commit_author = author_result.stdout.strip()

        return commit_hash, commit_message, commit_author
    except subprocess.CalledProcessError as e:
        print(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des infos du commit: {e}")
        return "unknown", "Commit inconnu", "unknown"

def get_file_content(filepath: str) -> str:
    """Lit le contenu d'un fichier avec gestion d'erreur d√©taill√©e"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if len(content) > 10000:
                print(f"üìÑ {filepath}: {len(content)} caract√®res")
            return content
    except UnicodeDecodeError:
        print(f"‚ö†Ô∏è Fichier {filepath} ignor√© (encodage non UTF-8)")
        return ""
    except Exception as e:
        print(f"‚ùå Erreur lecture {filepath}: {e}")
        return ""

def analyze_code(files_content: str) -> Optional[str]:
    """Envoie le code √† l'IA pour analyse via la Responses API avec retry"""
    if not files_content:
        print("‚ùå Aucun contenu √† analyser")
        return None

    # Prompt am√©lior√© avec crit√®res d√©taill√©s et sans exemple biais√©
    prompt = f"""
Tu es un code reviewer senior expert. Analyse les CHANGEMENTS de code ci-dessous et √©value-les selon des crit√®res stricts.

CRIT√àRES D'√âVALUATION (sur 20) :

1. **SOLID** (0-20) - Principes de conception :
   - Single Responsibility : Chaque classe/fonction a-t-elle une seule raison de changer ?
   - Open/Closed : Le code est-il extensible sans modification ?
   - Liskov Substitution : Les h√©ritages sont-ils corrects ?
   - Interface Segregation : Pas de d√©pendances inutiles ?
   - Dependency Inversion : D√©pendances vers abstractions ?
   - NOTE : 0-5=Tr√®s mauvais, 6-10=Insuffisant, 11-14=Correct, 15-17=Bon, 18-20=Excellent

2. **Clart√©** (0-20) - Lisibilit√© et maintenabilit√© :
   - Nommage explicite et coh√©rent ?
   - Structure logique et organisation claire ?
   - Complexit√© cognitive faible ?
   - Documentation/commentaires pertinents (pas excessifs) ?
   - NOTE : 0-5=Illisible, 6-10=Confus, 11-14=Acceptable, 15-17=Clair, 18-20=Exemplaire

3. **S√©curit√©** (0-20) - Bonnes pratiques et vuln√©rabilit√©s :
   - Validation des entr√©es utilisateur ?
   - Pas d'injection (SQL, XSS, etc.) ?
   - Gestion s√©curis√©e des erreurs (pas d'exposition de secrets) ?
   - Authentification/autorisation appropri√©es ?
   - Pas de d√©pendances vuln√©rables ?
   - NOTE : 0-5=Dangereuses vuln√©rabilit√©s, 6-10=Risques significatifs, 11-14=Basique, 15-17=S√©curis√©, 18-20=Niveau production

4. **Performance** (0-20) - Efficacit√© et optimisation :
   - Complexit√© algorithmique appropri√©e (O(n) vs O(n¬≤), etc.) ?
   - Utilisation efficace de la m√©moire (pas de fuites, copies inutiles) ?
   - Requ√™tes base de donn√©es optimis√©es (N+1 queries, indexation) ?
   - Mise en cache pertinente ?
   - Pas de calculs redondants ou boucles inutiles ?
   - Chargement lazy/eager appropri√© ?
   - NOTE : 0-5=Tr√®s inefficace, 6-10=Probl√®mes notables, 11-14=Acceptable, 15-17=Optimis√©, 18-20=Hautement performant

**SCORE GLOBAL** : Moyenne pond√©r√©e des 4 crit√®res (pas juste la moyenne arithm√©tique).
- P√©nalise fortement les scores <10 dans une cat√©gorie
- Un excellent code peut avoir 16-18/20
- 20/20 est exceptionnel et tr√®s rare (code production parfait)
- Un code m√©diocre doit avoir 8-12/20, pas 15/20
- Consid√®re SOLID, Clart√©, S√©curit√© ET Performance dans le calcul

CONSIGNES STRICTES :
- Sois OBJECTIF et EXIGEANT dans ta notation
- Varie les notes selon la QUALIT√â R√âELLE du code
- Ne donne PAS syst√©matiquement 14-16/20
- Un petit changement cosm√©tique m√©rite 8-11/20
- Un refactoring majeur bien fait m√©rite 15-18/20
- Identifie 2-4 points forts ET 2-4 points faibles r√©els

RETOURNE UNIQUEMENT CE JSON (sans ```json, sans texte avant/apr√®s) :
{{
    "score_global": <nombre 0-20>,
    "details": {{
        "SOLID": <nombre 0-20>,
        "Clarte": <nombre 0-20>,
        "Securite": <nombre 0-20>,
        "Performance": <nombre 0-20>
    }},
    "resume": "<phrase courte r√©sumant l'analyse>",
    "points_forts": ["<point fort 1>", "<point fort 2>"],
    "points_faibles": ["<point faible 1>", "<point faible 2>"],
    "conseil_mentor": "<conseil concret et actionnable pour am√©liorer le code>"
}}

CHANGEMENTS √Ä ANALYSER :
{files_content}

RAPPEL : Retourne UNIQUEMENT le JSON, sans markdown, sans explications."""

    max_retries = 2
    for attempt in range(max_retries):
        try:
            print(f"ü§ñ Tentative {attempt + 1}/{max_retries} d'analyse IA...")
            response = client.responses.create(
                model=MODEL_NAME,
                input=[
                    {"role": "system", "content": "You are a senior code reviewer API. You output ONLY valid JSON, no markdown, no explanations. Be critical and objective in your scoring - vary scores based on actual code quality."},
                    {"role": "user", "content": prompt}
                ],
                reasoning={"effort": "medium"}  # Augment√© pour analyse approfondie
            )

            output = response.output_text.strip()
            print(f"‚úÖ R√©ponse IA re√ßue ({len(output)} caract√®res)")
            return output

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur API OpenAI (tentative {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                print(f"‚ùå √âchec d√©finitif apr√®s {max_retries} tentatives")
                return None

    return None

def get_discord_mention(author: str) -> str:
    """Retourne la mention Discord de l'auteur si connu, sinon le nom"""
    # Normalise le nom (lowercase et supprime les espaces)
    author_normalized = author.lower().strip().replace(" ", "")

    # Cherche dans le mapping
    discord_id = AUTHOR_DISCORD_MAP.get(author_normalized)

    if discord_id:
        return f"<@{discord_id}>"
    else:
        return author

def send_discord_notification(report_json: str, commit_hash: str, commit_message: str, commit_author: str, change_context: str = "") -> bool:
    """Envoie le rapport format√© sur Discord avec validation stricte"""
    try:
        # Nettoyage des balises Markdown et espaces
        cleaned_json = report_json.replace("```json", "").replace("```", "").strip()
        
        # Nettoyage suppl√©mentaire : extraction du JSON si du texte est pr√©sent avant/apr√®s
        # Cherche le premier { et le dernier }
        start_idx = cleaned_json.find('{')
        end_idx = cleaned_json.rfind('}')
        
        if start_idx != -1 and end_idx != -1:
            cleaned_json = cleaned_json[start_idx:end_idx+1]
        
        # Tentative de parsing JSON brut
        try:
            raw_data = json.loads(cleaned_json)
        except json.JSONDecodeError as e:
            print(f"‚ùå JSON invalide re√ßu de l'IA: {e}")
            print(f"Extrait du contenu: {cleaned_json[:500]}...")
            return False
        
        # Validation stricte avec Pydantic
        try:
            validated_report = ReviewReport(**raw_data)
        except ValidationError as e:
            print(f"‚ùå Sch√©ma JSON invalide (validation Pydantic √©chou√©e):")
            print(e)
            print(f"Donn√©es re√ßues: {raw_data}")
            return False
        
        # Conversion en dict avec donn√©es valid√©es et sanit√©es
        data = validated_report.model_dump()
        
        # Couleur selon la note (Vert >= 15, Orange >= 10, Rouge < 10)
        score = data['score_global']
        if score >= 15:
            color = 5763719  # Vert
        elif score >= 10:
            color = 16776960  # Orange
        else:
            color = 15548997  # Rouge

        # Sanitation suppl√©mentaire pour Discord (limitation de longueur des fields)
        points_forts_text = "\n".join([f"‚Ä¢ {p[:150]}" for p in data['points_forts'][:5]]) or "Aucun"
        points_faibles_text = "\n".join([f"‚Ä¢ {p[:150]}" for p in data['points_faibles'][:5]]) or "Aucun"
        
        # Limitation stricte des longueurs Discord (max 1024 par field)
        if len(points_forts_text) > 1024:
            points_forts_text = points_forts_text[:1020] + "..."
        if len(points_faibles_text) > 1024:
            points_faibles_text = points_faibles_text[:1020] + "..."

        # Construction de la description avec contexte des changements
        author_mention = get_discord_mention(commit_author)
        description = f"**{commit_message[:100]}** (`{commit_hash}`)\n"
        description += f"üë§ Auteur : {author_mention}\n"
        if change_context:
            description += f"üì¶ {change_context}\n"
        description += f"\n{data['resume'][:200]}"

        embed = {
            "title": f"üìù Code Review : {score}/20",
            "description": description,
            "color": color,
            "fields": [
                {"name": "üß† SOLID", "value": f"{data['details']['SOLID']}/20", "inline": True},
                {"name": "üëÄ Clart√©", "value": f"{data['details']['Clarte']}/20", "inline": True},
                {"name": "üõ°Ô∏è S√©curit√©", "value": f"{data['details']['Securite']}/20", "inline": True},
                {"name": "‚ö° Performance", "value": f"{data['details']['Performance']}/20", "inline": True},
                {"name": "‚úÖ Top", "value": points_forts_text, "inline": False},
                {"name": "‚ö†Ô∏è Flop", "value": points_faibles_text, "inline": False},
                {"name": "üí° Conseil", "value": data['conseil_mentor'][:300], "inline": False}
            ],
            "footer": {"text": f"Moteur: {MODEL_NAME} ‚Ä¢ CulturiaQuests CI/CD"}
        }

        # Pr√©pare le payload avec mention de l'auteur
        payload = {"embeds": [embed]}

        # Ajoute une mention en texte si l'auteur est connu (pour notifier)
        if author_mention.startswith("<@"):
            payload["content"] = f"{author_mention} Nouvelle code review disponible !"

        response = requests.post(DISCORD_WEBHOOK, json=payload, timeout=10)
        
        if response.status_code == 204:
            print("‚úÖ Rapport envoy√© sur Discord avec succ√®s")
            return True
        else:
            print(f"‚ö†Ô∏è Discord a r√©pondu avec le code {response.status_code}")
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erreur r√©seau Discord: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Erreur inattendue lors de l'envoi Discord: {e}")
        return False

if __name__ == "__main__":
    print("="*60)
    print("ü§ñ AI Code Reviewer - CulturiaQuests")
    print("="*60)
    
    # V√©rification des variables d'environnement
    if not API_KEY:
        print("‚ùå OPENAI_API_KEY non d√©finie")
        sys.exit(1)
    if not DISCORD_WEBHOOK:
        print("‚ùå DISCORD_WEBHOOK_URL non d√©finie")
        sys.exit(1)
    
    changed_files = get_changed_files()
    
    if not changed_files:
        print("‚ÑπÔ∏è Aucun fichier de code pertinent modifi√©.")
        sys.exit(0)

    # R√©cup√©ration des informations du commit
    commit_hash, commit_message, commit_author = get_commit_info()
    print(f"üìå Commit: {commit_message} ({commit_hash})")
    print(f"üë§ Auteur: {commit_author}")

    print(f"\nüìã Fichiers d√©tect√©s: {len(changed_files)}")
    for f in changed_files:
        print(f"  - {f}")
    
    print(f"\nüöÄ Analyse IA en cours avec {MODEL_NAME}...\n")

    content_to_analyze = ""
    total_chars = 0
    total_added = 0
    total_deleted = 0

    for file in changed_files:
        # R√©cup√©ration du diff au lieu du contenu complet
        file_diff = get_file_diff(file)
        stats = get_file_stats(file)

        total_added += stats['added']
        total_deleted += stats['deleted']

        total_chars += len(file_diff)

    # D√©termine l'ampleur du changement
    total_changes = total_added + total_deleted
    if total_changes < 10:
        change_magnitude = "TR√àS PETIT (ajustement mineur)"
    elif total_changes < 50:
        change_magnitude = "PETIT (modification simple)"
    elif total_changes < 200:
        change_magnitude = "MOYEN (feature ou refactoring)"
    else:
        change_magnitude = "IMPORTANT (refactoring majeur ou nouvelle feature)"

    # En-t√™te contextuel enrichi
    content_to_analyze = f"""
CONTEXTE DU COMMIT :
Commit: {commit_hash}
Message: {commit_message}
Fichiers modifi√©s: {len(changed_files)}
Ampleur: {change_magnitude} (+{total_added}/-{total_deleted} lignes)

CONSIGNE D'√âVALUATION :
L'ampleur des changements doit influencer ta notation :
- Changement tr√®s petit (<10 lignes) : Si c'est juste cosm√©tique ou trivial, note 8-12/20. Si c'est un fix critique bien fait, note 13-16/20.
- Changement petit (10-50 lignes) : √âvalue la qualit√© technique. Code basique: 10-13/20, code solide: 14-16/20.
- Changement moyen (50-200 lignes) : Potentiel pour excellentes notes si bien architectur√© (15-18/20).
- Changement important (>200 lignes) : √âvalue la coh√©rence globale et l'architecture (12-18/20 selon qualit√©).

INSTRUCTIONS :
Analyse les changements ci-dessous (format diff git).
- Les lignes '+' sont des ajouts, les lignes '-' sont des suppressions
- √âvalue la QUALIT√â de ces CHANGEMENTS, pas du fichier complet
- Sois CRITIQUE et VARIE tes notes selon la vraie qualit√©

"""

    # Ajout des diffs de chaque fichier
    for file in changed_files:
        file_diff = get_file_diff(file)
        stats = get_file_stats(file)

        content_to_analyze += f"\n{'='*60}\n"
        content_to_analyze += f"FICHIER: {file}\n"
        content_to_analyze += f"Lignes ajout√©es: +{stats['added']} | Lignes supprim√©es: -{stats['deleted']}\n"
        content_to_analyze += f"{'='*60}\n"
        content_to_analyze += file_diff if file_diff else "[Nouveau fichier ou fichier binaire]\n"
        content_to_analyze += "\n"

    print(f"üìä Changements d√©tect√©s: {change_magnitude}")
    print(f"üìä D√©tails: +{total_added} / -{total_deleted} lignes sur {len(changed_files)} fichier(s)")
    print(f"üìä Total √† analyser: {total_chars} caract√®res")
    
    # Troncation de s√©curit√© avec logging d√©taill√©
    if len(content_to_analyze) > MAX_CONTENT_LENGTH:
        original_length = len(content_to_analyze)
        content_to_analyze = content_to_analyze[:MAX_CONTENT_LENGTH]
        truncated_chars = original_length - MAX_CONTENT_LENGTH
        print(f"‚ö†Ô∏è Contenu tronqu√©: {truncated_chars} caract√®res supprim√©s (limite: {MAX_CONTENT_LENGTH})")
        print(f"‚ö†Ô∏è Cela repr√©sente {(truncated_chars/original_length)*100:.1f}% du contenu total")
        content_to_analyze += f"\n\n... [TRONQU√â: {truncated_chars} caract√®res omis] ..."

    report = analyze_code(content_to_analyze)

    if report:
        # Ajout du contexte des changements pour la notification Discord
        change_context = f"{len(changed_files)} fichier(s) ‚Ä¢ +{total_added}/-{total_deleted} lignes"
        success = send_discord_notification(report, commit_hash, commit_message, commit_author, change_context)
        if success:
            print("\n" + "="*60)
            print("‚úÖ Workflow termin√© avec succ√®s")
            print("="*60)
            sys.exit(0)
        else:
            print("\n" + "="*60)
            print("‚ö†Ô∏è Analyse termin√©e mais √©chec d'envoi Discord")
            print("="*60)
            sys.exit(1)
    else:
        print("\n" + "="*60)
        print("‚ùå √âchec de l'analyse IA")
        print("="*60)
        sys.exit(1)